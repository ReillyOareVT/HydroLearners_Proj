{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337662ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Apr 22 17:01:59 2025\n",
    "\n",
    "@author: malif\n",
    "\"\"\"\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Data availability analysis for EStreams project\n",
    "- Analyze streamflow and meteorology data completeness\n",
    "- Identify basins with full data coverage\n",
    "Created on Mon Apr 21, 2025\n",
    "@author: malif\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393a2958",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dbeaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "streamflow_file = r\"D:\\VT_SPR2025\\CEE5984_Machine Learning in Water Resources\\GroupProject\\01_EStreams_Data\\EStreams\\streamflow_indices\\weekly\\weekly_streamflow_mean.csv\"\n",
    "streamflow_df = pd.read_csv(streamflow_file, parse_dates=True, index_col=0)\n",
    "\n",
    "# List of basin IDs\n",
    "basin_ids = streamflow_df.columns.tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4451c151",
   "metadata": {},
   "outputs": [],
   "source": [
    "streamflow_start = \"1940-01-01\"\n",
    "streamflow_end = \"2020-12-31\"\n",
    "\n",
    "streamflow_df_period = streamflow_df.loc[streamflow_start:streamflow_end]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d451a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "streamflow_availability = pd.DataFrame({\n",
    "    'Non-NaN Count': streamflow_df_period.notna().sum(),\n",
    "    'Availability (%)': 100 * streamflow_df_period.notna().sum() / len(streamflow_df_period)\n",
    "})\n",
    "\n",
    "# Sort basins by descending availability\n",
    "streamflow_availability = streamflow_availability.sort_values(by='Availability (%)', ascending=False)\n",
    "\n",
    "# Identify basins with 100% data availability\n",
    "full_streamflow_basins = streamflow_availability[streamflow_availability['Availability (%)'] == 100]\n",
    "full_streamflow_basin_ids = full_streamflow_basins.index.tolist()\n",
    "\n",
    "print(f\"Number of basins with full streamflow data ({streamflow_start} to {streamflow_end}): {len(full_streamflow_basin_ids)}\")\n",
    "\n",
    "# Subset dataframe to only basins with full streamflow data\n",
    "streamflow_full_df = streamflow_df_period[full_streamflow_basin_ids]\n",
    "print(\"\\nSubset of basins with complete streamflow data:\")\n",
    "print(streamflow_full_df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431b7831",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Meteorology data folder\n",
    "meteorology_folder = r\"D:\\VT_SPR2025\\CEE5984_Machine Learning in Water Resources\\GroupProject\\01_EStreams_Data\\EStreams\\meteorology\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159cf4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_missingness(basin_list, start_date=None, end_date=None):\n",
    "    missingness_summary = {}\n",
    "    \n",
    "    for basin_id in basin_list:\n",
    "        file_path = os.path.join(meteorology_folder, f\"estreams_meteorology_{basin_id}.csv\")\n",
    "        \n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"Warning: Meteorology file not found for basin {basin_id}\")\n",
    "            continue\n",
    "        \n",
    "        # Read meteorology data\n",
    "        meteo_df = pd.read_csv(file_path, parse_dates=True, index_col=0)\n",
    "        \n",
    "        # Subset to specified period if provided\n",
    "        if start_date and end_date:\n",
    "            meteo_df = meteo_df.loc[start_date:end_date]\n",
    "        \n",
    "        # Calculate missing percentage\n",
    "        missing_percentage = (meteo_df.isna().sum() / len(meteo_df)) * 100\n",
    "        missingness_summary[basin_id] = missing_percentage\n",
    "    \n",
    "    # Return as DataFrame\n",
    "    return pd.DataFrame(missingness_summary).T\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc91147",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_meteo_full_df = calculate_missingness(full_streamflow_basin_ids)\n",
    "\n",
    "print(\"\\nMissing meteorology data (% missing) for full streamflow basins (full record):\")\n",
    "print(missing_meteo_full_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e7cf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo_start = \"1940-01-01\"\n",
    "meteo_end = \"2020-12-31\"\n",
    "\n",
    "missing_meteo_period_df = calculate_missingness(full_streamflow_basin_ids, start_date=meteo_start, end_date=meteo_end)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89ba4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f\"\\nMissing meteorology data (% missing) for {meteo_start} to {meteo_end}:\")\n",
    "print(missing_meteo_period_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038e88af",
   "metadata": {},
   "outputs": [],
   "source": [
    "basins_with_full_meteo = missing_meteo_period_df[(missing_meteo_period_df == 0).all(axis=1)].index.tolist()\n",
    "\n",
    "print(f\"\\nNumber of basins with complete meteorology data ({meteo_start}–{meteo_end}): {len(basins_with_full_meteo)}\")\n",
    "print(\"Basins with full meteorology data:\", basins_with_full_meteo)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836c74e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the analysis period\n",
    "analysis_start = \"1980-01-01\"\n",
    "analysis_end = \"2020-12-31\"\n",
    "years_range = pd.date_range(start=analysis_start, end=analysis_end, freq='Y').year\n",
    "\n",
    "# Meteorological parameters of interest (example: update if needed)\n",
    "meteo_parameters = ['p_mean', 't_mean', 't_min', 't_max', 'sp_mean', 'rh_mean', 'ws_mean', 'swr_mean', 'pet_mean']\n",
    "\n",
    "# Initialize dictionaries to store per-parameter missingness data\n",
    "yearly_missingness_per_parameter = {param: {} for param in meteo_parameters}\n",
    "\n",
    "# Loop through each basin\n",
    "for basin_id in full_streamflow_basin_ids:\n",
    "    file_path = os.path.join(meteorology_folder, f\"estreams_meteorology_{basin_id}.csv\")\n",
    "    \n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"Warning: Meteorology file not found for basin {basin_id}\")\n",
    "        continue\n",
    "    \n",
    "    # Load the meteorology data\n",
    "    meteo_df = pd.read_csv(file_path, parse_dates=True, index_col=0)\n",
    "    \n",
    "    # Subset to analysis period\n",
    "    meteo_df = meteo_df.loc[analysis_start:analysis_end]\n",
    "    \n",
    "    # Check if all desired parameters exist\n",
    "    available_parameters = [param for param in meteo_parameters if param in meteo_df.columns]\n",
    "    \n",
    "    # Calculate % missing per year for each parameter\n",
    "    for param in available_parameters:\n",
    "        # Group by year\n",
    "        yearly_group = meteo_df[param].groupby(meteo_df.index.year)\n",
    "        \n",
    "        # Calculate missing % for each year\n",
    "        missing_percentage_by_year = yearly_group.apply(lambda x: x.isna().sum() / len(x) * 100)\n",
    "        \n",
    "        # Store result\n",
    "        if basin_id not in yearly_missingness_per_parameter[param]:\n",
    "            yearly_missingness_per_parameter[param][basin_id] = missing_percentage_by_year\n",
    "\n",
    "# Create a separate DataFrame for each meteorological parameter\n",
    "parameter_missingness_dfs = {}\n",
    "\n",
    "for param, basin_data in yearly_missingness_per_parameter.items():\n",
    "    # Convert dictionary to DataFrame\n",
    "    df_missingness = pd.DataFrame(basin_data).T  # basins as rows, years as columns\n",
    "    df_missingness = df_missingness.reindex(columns=years_range)  # Ensure all years included\n",
    "    parameter_missingness_dfs[param] = df_missingness\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d675d41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a645450f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Create a heatmap for each parameter\n",
    "for param, missing_df in parameter_missingness_dfs.items():\n",
    "    plt.figure(figsize=( missing_df.shape[1] * 0.7,  missing_df.shape[0] * 0.4))  \n",
    "    # Width scales with years, height scales with number of basins\n",
    "\n",
    "    sns.heatmap(\n",
    "        missing_df, \n",
    "        cmap='coolwarm', \n",
    "        vmin=0, vmax=100,  # Fix color scale from 0 to 100% missing\n",
    "        cbar_kws={'label': '% Missing Data'},\n",
    "        linewidths=0.0,  # Fine gridlines\n",
    "        linecolor='gray'\n",
    "    )\n",
    "    \n",
    "    plt.title(f\"Heatmap of % Missing Data per Year for {param}\", fontsize=18)\n",
    "    plt.xlabel(\"Year\", fontsize=5)\n",
    "    plt.ylabel(\"Basin ID\", fontsize=5)\n",
    "\n",
    "    # Optionally: simplify axis ticks if too many\n",
    "    # if missing_df.shape[0] > 50:\n",
    "    #     plt.yticks([], [])  # Hide basin IDs\n",
    "    # if missing_df.shape[1] > 40:\n",
    "    #     plt.xticks([], [])  # Hide year labels\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa837f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "\n",
    "# Optional: open in browser for better experience in Spyder\n",
    "pio.renderers.default = 'browser'\n",
    "\n",
    "def plot_interactive_heatmap(df, title=\"Interactive Heatmap\", color_scale=\"RdBu_r\"):\n",
    "    import plotly.express as px\n",
    "    import plotly.io as pio\n",
    "\n",
    "    # Optional: make it open in browser if using Spyder\n",
    "    pio.renderers.default = 'browser'\n",
    "\n",
    "    fig = px.imshow(\n",
    "        df.values,\n",
    "        labels=dict(x=\"Year\", y=\"Basin ID\", color=\"% Missing\"),\n",
    "        x=df.columns,\n",
    "        y=df.index,\n",
    "        color_continuous_scale=color_scale,  # ✅ use 'RdBu_r' instead of 'coolwarm'\n",
    "        zmin=0, zmax=100\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        xaxis_title=\"Year\",\n",
    "        yaxis_title=\"Basin ID\",\n",
    "        width=max(1000, len(df.columns) * 20),\n",
    "        height=max(600, len(df) * 12),\n",
    "        font=dict(size=12)\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db26afd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_interactive_heatmap(parameter_missingness_dfs['p_mean'], \n",
    "                         title=\"Interactive Heatmap of % Missing PRCP\", \n",
    "                         color_scale=\"RdBu_r\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
